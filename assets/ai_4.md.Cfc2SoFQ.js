import{_ as t,c as e,o as r,ag as o}from"./chunks/framework.BXwhd-1y.js";const u=JSON.parse('{"title":"AI 核心概念速览","description":"","frontmatter":{},"headers":[],"relativePath":"ai/4.md","filePath":"ai/4.md","lastUpdated":1757854372000}'),l={name:"ai/4.md"};function i(n,a,p,s,c,m){return r(),e("div",null,a[0]||(a[0]=[o('<h1 id="ai-核心概念速览" tabindex="-1">AI 核心概念速览 <a class="header-anchor" href="#ai-核心概念速览" aria-label="Permalink to &quot;AI 核心概念速览&quot;">​</a></h1><h2 id="🔥llm-large-language-model" tabindex="-1">🔥LLM（Large Language Model） <a class="header-anchor" href="#🔥llm-large-language-model" aria-label="Permalink to &quot;🔥LLM（Large Language Model）&quot;">​</a></h2><p>LLM 即「大语言模型」，是一种基于深度学习的自然语言处理技术。<br> 它通过海量文本语料进行预训练，掌握语言规律与知识，从而具备理解与生成自然语言的能力。<br> 你可以把它想象成一位博览群书、过目不忘的“超级学生”——但这位学生目前只能“阅读文字”。</p><blockquote><p>注意：LLM 本身只处理文本。多模态 AI 助手中的语音识别、图像理解等能力，是 LLM 与音频/视觉模型协同工作的结果。<br> 举例：你上传一张猫咪照片并问“它在做什么？”<br> 系统先用视觉模型提取“橘猫、窗台、阳光、伸爪”等关键信息，再将这些特征转成文本描述，最终由 LLM 润色输出：“这只橘猫正慵懒地躺在洒满阳光的窗台上伸爪打哈欠。”</p></blockquote><h2 id="🌈agent-智能体" tabindex="-1">🌈Agent（智能体） <a class="header-anchor" href="#🌈agent-智能体" aria-label="Permalink to &quot;🌈Agent（智能体）&quot;">​</a></h2><p>Agent 原意为“代理”。与“你问一句它答一句”的聊天机器人不同，Agent 更像一位<strong>具备行动力的同事</strong>：<br> 你给它一个目标，它会自主拆解任务、调用工具、做出决策，直至完成使命。</p><ul><li>LLM 是“大脑”——负责理解与规划；</li><li>Agent 是“大脑 + 四肢”——不仅能思考，还能动手。</li></ul><blockquote><p>当下常见的 AI 助手大多是“半 Agent”：它们能帮你查航班、列选项，却未必能直接替你下单付款。未来，这些助手将逐步进化为真正的全功能 Agent。</p></blockquote><h2 id="🌈prompt-提示词" tabindex="-1">🌈Prompt（提示词） <a class="header-anchor" href="#🌈prompt-提示词" aria-label="Permalink to &quot;🌈Prompt（提示词）&quot;">​</a></h2><p>Prompt 的字面意思是“提示”，在 AI 语境下指<strong>引导 LLM 理解任务的方式</strong>。 文末附Prompt精选大全。 你可以细分为 <strong>User Prompt</strong> 与 <strong>System Prompt</strong>。</p><h3 id="user-prompt-vs-system-prompt" tabindex="-1">User Prompt vs. System Prompt <a class="header-anchor" href="#user-prompt-vs-system-prompt" aria-label="Permalink to &quot;User Prompt vs. System Prompt&quot;">​</a></h3><p>自 2023 年 GPT-3 发布以来，主流交互形式仍是“对话”。</p><ul><li><strong>User Prompt</strong>：你在对话框里输入的任何问题或陈述，例如“如何用 Excel 做透视表？”</li><li><strong>System Prompt</strong>：由系统提前写好的“人设脚本”，包含背景、语气、角色、约束等。<br> 当你选择“法律顾问”或“Excel 专家”等预设角色时，后台其实加载了一段 System Prompt，省去你每次手动描述的麻烦。</li></ul><h3 id="为什么-prompt-如此重要" tabindex="-1">为什么 Prompt 如此重要？ <a class="header-anchor" href="#为什么-prompt-如此重要" aria-label="Permalink to &quot;为什么 Prompt 如此重要？&quot;">​</a></h3><p>同样的句子，不同人会给出截然不同的回应——</p><ul><li>对父母说“我有点头疼”，他们会问“吃药了吗？要不要去医院？”</li><li>对领导说，领导可能回“需要请假休息吗？”</li><li>对损友，他可能回“恭喜恭喜”并配个沙雕表情包。</li></ul><p>AI 面向所有用户，必须给出“通用”回答。若想让它扮演特定角色，就得用 Prompt 事先“设定语境”。<br> Prompt 的质量，往往直接决定输出的质量。</p><h2 id="🔥mcp-model-context-protocol-与-function-calling" tabindex="-1">🔥MCP（Model Context Protocol）与 Function Calling <a class="header-anchor" href="#🔥mcp-model-context-protocol-与-function-calling" aria-label="Permalink to &quot;🔥MCP（Model Context Protocol）与 Function Calling&quot;">​</a></h2><h3 id="function-calling-简述" tabindex="-1">Function Calling 简述 <a class="header-anchor" href="#function-calling-简述" aria-label="Permalink to &quot;Function Calling 简述&quot;">​</a></h3><p>大模型本身无法直接访问实时外部数据。<br> 例如，在不开启联网搜索的情况下，你问 DeepSeek “杭州明天天气如何？” 它甚至不知道“明天”是几号。<br> 开启联网后，模型会调用内部封装的“天气查询函数”（Function Calling），访问外部 API 获取数据，再生成最终回复。</p><h3 id="mcp-ai-的-usb-c-接口" tabindex="-1">MCP：AI 的 “USB-C 接口” <a class="header-anchor" href="#mcp-ai-的-usb-c-接口" aria-label="Permalink to &quot;MCP：AI 的 “USB-C 接口”&quot;">​</a></h3><p>Function Calling 的实现方式各家不同，导致重复造轮子。<br> MCP（Model Context Protocol）为此而生：它是一套开放协议，定义了 AI 与外部世界交互的标准接口。</p><ul><li>开发者可以按 MCP 规范编写插件（如天气查询、股票行情、数据库检索）。</li><li>任何兼容 MCP 的 AI 助手都能直接调用这些插件，无需重复对接。</li></ul><p>一句话总结：MCP 让“工具”像 USB-C 设备一样，即插即用，跨平台共享。现在每个ai助手都有联网搜索功能，但是每个ai助手的联网搜索功能的实现方式可能都不一样，有没有办法统一实现呢？ MCP就是做这个的，你可以自己开发一个「插件」，可以查询实时天气（可能只是调用外部的api），但是要符合MCP的规范。 别的ai助手支持MCP的话，ai助手内部识别到要查询天气的时候就可以调用你开发的「插件」去查询天气。多个ai助手共用这个一个 「插件」就可以了。</p><h3 id="mcp比如想象的更强大" tabindex="-1">MCP比如想象的更强大 <a class="header-anchor" href="#mcp比如想象的更强大" aria-label="Permalink to &quot;MCP比如想象的更强大&quot;">​</a></h3><p>MCP 不仅能查询天气、股票这类在线数据，甚至还能<strong>直接操作本地文件与软件</strong>。只要按协议开发插件，就能让 AI 帮你“动鼠标、敲键盘”。</p><p>🌰</p><ul><li>你对 AI 说：“把本周的销售 Excel 汇总成图表并发邮件给老板。”</li><li>AI 通过 MCP 调用本地插件：<br> • 读取 <code>~/Documents/sales.xlsx</code> 中的最新数据；<br> • 生成柱状图并保存为 PNG；<br> • 打开邮件客户端，自动填写收件人、主题、正文，并附上图片；<br> • 你只需点“发送”即可。</li></ul><h3 id="附" tabindex="-1">附 <a class="header-anchor" href="#附" aria-label="Permalink to &quot;附&quot;">​</a></h3><ol><li><a href="https://github.com/langgptai/wonderful-prompts?tab=readme-ov-file#%E9%80%9A%E7%94%A8%E8%B6%85%E7%BA%A7-prompt-" target="_blank" rel="noreferrer">Prompts精选（飞书）</a></li><li><a href="https://prompts.chat" target="_blank" rel="noreferrer">awesome Prompts(英文)</a></li><li><a href="https://aiduck.netlify.app/" target="_blank" rel="noreferrer">ai导航（beta）</a></li></ol>',30)]))}const d=t(l,[["render",i]]);export{u as __pageData,d as default};
