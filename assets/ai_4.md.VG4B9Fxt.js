import{_ as e,c as o,o as a,ad as r}from"./chunks/framework.CMzpCLzZ.js";const P=JSON.parse('{"title":"","description":"","frontmatter":{},"headers":[],"relativePath":"ai/4.md","filePath":"ai/4.md","lastUpdated":1754040745000}'),p={name:"ai/4.md"};function l(n,t,i,s,m,c){return a(),o("div",null,t[0]||(t[0]=[r('<h2 id="llm" tabindex="-1">LLM <a class="header-anchor" href="#llm" aria-label="Permalink to &quot;LLM&quot;">​</a></h2><p>LLM 即 Large Language Model，大语言模型。 是一种基于深度学习的自然语言处理技术，通过海量文本数据训练，能够生成或理解自然语言文本。 可以把它想象成一个阅读了海量信息（书籍、文章、网页）， 并记住了其中语言模式和知识的“超级学生”。</p><p>LLM只处理文字，在一些多模态AI助手中的音频解析等能力是结合了视频或音频模型的。 例如，你上传一张猫咪照片并提问：“它在做什么？” 多模态系统会先用视觉模型“看图说话”，提炼出毛色、姿态、环境等关键信息；<br> 接着将这些视觉特征转成文本描述，交由 LLM 最终润色输出：“这只猫正慵懒地躺在洒满阳光的窗台上，伸着爪子打哈欠。”</p><h2 id="agent" tabindex="-1">Agent <a class="header-anchor" href="#agent" aria-label="Permalink to &quot;Agent&quot;">​</a></h2><p>Agent原义代理，它不是“你问一句它答一句”的聊天机器人，而是你给它一个目标，它就能像真人一样<strong>查资料、做决策、调用工具</strong>，直到任务完成。<br> Agent = LLM 的“行动版” —— 它不只聊天，还能调用工具、自主决策、帮你搞定任务，所以也成为智能体。</p><ul><li>LLM 是“大脑”（负责理解语言）</li><li>Agent 是“大脑+手脚”（理解后主动执行）</li></ul><blockquote><p>个人理解：我们在使用的多数ai助手都是基于LLM的半agent，且正在向全agent方向发展。比如你说让ai帮你定机票，它可能会帮你查找航班信息并推荐合适的航班，但并不会帮你支付下单机票。</p></blockquote><h2 id="prompt" tabindex="-1">Prompt <a class="header-anchor" href="#prompt" aria-label="Permalink to &quot;Prompt&quot;">​</a></h2><p>Prompt原意：提示，可以理解为LLM<strong>理解问题的方式</strong>。 它可以再分为<strong>User Prompt和 System Prompt</strong>。</p><h3 id="user-prompt-和-是system-prompt" tabindex="-1">User Prompt 和 是System Prompt <a class="header-anchor" href="#user-prompt-和-是system-prompt" aria-label="Permalink to &quot;User Prompt 和 是System Prompt&quot;">​</a></h3><p>从2023年OpenAI发布GPT-3模型一直到目前，多数AI看起来只是一个聊天框，我们通过聊天框发送一条消息给AI模型，然后AI模型再生成 一条回复消息，这个过程我们称之为对话。而我们发送的聊天消息，称之为User Prompt，也就是用户提示词，大部分的User Prompt一般 都是我们提出的问题或者想说的话。 而在我们发送的消息的时候，有些场景需要AI扮演某些角色，比如你想问AI office相关的问题，那么你就可以在提出问题之前先发送一条消息： “你是一名精通office的专家”，又或者你想咨询法律相关的问题，你可以发送：“你是一位xx方面的法律专家，打赢过无数场官司”， 此时我们发送的这些提示词就是User Prompt。</p><p>但是很多时候你在使用ai的时候，会有各种各样的问题和想法，来回给ai提示就会比较麻烦，所以在各个ai助手的软件或网站上就出现了各种各样的“角色”， 它是系统提前设定好“背景、语气、角色、性格”等方面的内容，当你需要什么样的“角色”时，直接新开会话即可，这些提前设定好的“角色”，是系统 预设好的提示词，我们称之为System Prompt。</p><h3 id="为什么需要prompt" tabindex="-1">为什么需要Prompt <a class="header-anchor" href="#为什么需要prompt" aria-label="Permalink to &quot;为什么需要Prompt&quot;">​</a></h3><p>当我们和人对话提出一个问题或者说出一句话时，即使是同样的语气，同样的词语，不同的人都会有不同的理解，回复的内容也会有差异。</p><p>比如我和不同的人说同样的话，我说：我有点头疼</p><p>爸妈：怎么回事，吃药了没有，去医院看看吗</p><p>领导：需要请假回去休息吗</p><p>朋友：“这是好事啊” （沙僧表情包）</p><p>因为ai是给所有用户使用的，它必须衡量各个方面，然后给你一个通用的回答，所以如果你想让ai充当什么样的角色，就需要提前发送Prompt。</p><h2 id="mcp-model-context-protocol" tabindex="-1">MCP（Model Context Protocol） <a class="header-anchor" href="#mcp-model-context-protocol" aria-label="Permalink to &quot;MCP（Model Context Protocol）&quot;">​</a></h2><p>MCP 是一套开放协议，用来标准化“AI 如何与外部世界交互”。你可以把它理解为AI的 <strong>USB-C 接口</strong>：</p><ul><li>插上就能读写本地文件、调用数据库、控制智能家居；</li><li>拔下就自动清理上下文，不留痕迹。<br> （MCP只是一个协议， 它定义了AI与外部世界交互的规则， 但是具体的实现由外部世界的开发者来完成。）</li></ul><p>我目前接触到的MCP，是vscode中的Cline插件，它利用MCP协议，实现了与外部世界的交互。</p>',23)]))}const h=e(p,[["render",l]]);export{P as __pageData,h as default};
