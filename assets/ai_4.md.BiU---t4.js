import{_ as a,c as e,o,ad as r}from"./chunks/framework.CMzpCLzZ.js";const h=JSON.parse('{"title":"几个 ai 相关的概念","description":"","frontmatter":{},"headers":[],"relativePath":"ai/4.md","filePath":"ai/4.md","lastUpdated":1754194056000}'),p={name:"ai/4.md"};function l(i,t,n,s,m,d){return o(),e("div",null,t[0]||(t[0]=[r('<h1 id="几个-ai-相关的概念" tabindex="-1">几个 ai 相关的概念 <a class="header-anchor" href="#几个-ai-相关的概念" aria-label="Permalink to &quot;几个 ai 相关的概念&quot;">​</a></h1><h2 id="🔥llm" tabindex="-1">🔥LLM <a class="header-anchor" href="#🔥llm" aria-label="Permalink to &quot;🔥LLM&quot;">​</a></h2><p>LLM 即 Large Language Model，大语言模型。 是一种基于深度学习的自然语言处理技术，通过海量文本数据训练，能够生成或理解自然语言文本。 可以把它想象成一个阅读了海量信息（书籍、文章、网页）， 并记住了其中语言模式和知识的“超级学生”。</p><p>LLM 只处理文字，在一些多模态 AI 助手中的音频解析等能力是结合了视频或音频模型的。 例如，你上传一张猫咪照片并提问：“它在做什么？” 多模态系统会先用视觉模型“看图说话”，提炼出毛色、姿态、环境等关键信息；<br> 接着将这些视觉特征转成文本描述，交由 LLM 最终润色输出：“这只猫正慵懒地躺在洒满阳光的窗台上，伸着爪子打哈欠。”</p><h2 id="🚀-agent" tabindex="-1">🚀 Agent <a class="header-anchor" href="#🚀-agent" aria-label="Permalink to &quot;🚀 Agent&quot;">​</a></h2><p>Agent 原义代理，它不是“你问一句它答一句”的聊天机器人，而是你给它一个目标，它就能像真人一样<strong>查资料、做决策、调用工具</strong>，直到任务完成。<br> Agent = LLM 的“行动版” —— 它不只聊天，还能调用工具、自主决策、帮你搞定任务，所以也成为智能体。</p><ul><li>LLM 是“大脑”（负责理解语言）</li><li>Agent 是“大脑+手脚”（理解后主动执行）</li></ul><blockquote><p>个人理解：我们在使用的多数 ai 助手都是基于 LLM 的半 agent，且正在向全 agent 方向发展。比如你说让 ai 帮你定机票，它可能会帮你查找航班信息并推荐合适的航班，但并不会帮你支付下单机票。</p></blockquote><h2 id="🔥prompt" tabindex="-1">🔥Prompt <a class="header-anchor" href="#🔥prompt" aria-label="Permalink to &quot;🔥Prompt&quot;">​</a></h2><p>Prompt 原意：提示，可以理解为 LLM<strong>理解问题的方式</strong>。 它可以再分为<strong>User Prompt 和 System Prompt</strong>。</p><h3 id="user-prompt-和-是-system-prompt" tabindex="-1">User Prompt 和 是 System Prompt <a class="header-anchor" href="#user-prompt-和-是-system-prompt" aria-label="Permalink to &quot;User Prompt 和 是 System Prompt&quot;">​</a></h3><p>从 2023 年 OpenAI 发布 GPT-3 模型一直到目前，多数 AI 看起来只是一个聊天框，我们通过聊天框发送一条消息给 AI 模型，然后 AI 模型再生成 一条回复消息，这个过程我们称之为对话。而我们发送的聊天消息，称之为 User Prompt，也就是用户提示词，大部分的 User Prompt 一般 都是我们提出的问题或者想说的话。 而在我们发送的消息的时候，有些场景需要 AI 扮演某些角色，比如你想问 AI office 相关的问题，那么你就可以在提出问题之前先发送一条消息： “你是一名精通 office 的专家”，又或者你想咨询法律相关的问题，你可以发送：“你是一位 xx 方面的法律专家，打赢过无数场官司”， 此时我们发送的这些提示词就是 User Prompt。</p><p>但是很多时候你在使用 ai 的时候，会有各种各样的问题和想法，来回给 ai 提示就会比较麻烦，所以在各个 ai 助手的软件或网站上就出现了各种各样的“角色”， 它是系统提前设定好“背景、语气、角色、性格”等方面的内容，当你需要什么样的“角色”时，直接新开会话即可，这些提前设定好的“角色”，是系统 预设好的提示词，我们称之为 System Prompt。</p><h3 id="为什么需要-prompt" tabindex="-1">为什么需要 Prompt <a class="header-anchor" href="#为什么需要-prompt" aria-label="Permalink to &quot;为什么需要 Prompt&quot;">​</a></h3><p>当我们和人对话提出一个问题或者说出一句话时，即使是同样的语气，同样的词语，不同的人都会有不同的理解，回复的内容也会有差异。</p><p>比如我和不同的人说同样的话，我说：我有点头疼</p><p>爸妈：怎么回事，吃药了没有，去医院看看吗</p><p>领导：需要请假回去休息吗</p><p>朋友：“这是好事啊” （沙僧表情包）</p><p>因为 ai 是给所有用户使用的，它必须衡量各个方面，然后给你一个通用的回答，所以如果你想让 ai 充当什么样的角色，就需要提前发送 Prompt。</p><h2 id="🔥mcp-model-context-protocol" tabindex="-1">🔥MCP（Model Context Protocol） <a class="header-anchor" href="#🔥mcp-model-context-protocol" aria-label="Permalink to &quot;🔥MCP（Model Context Protocol）&quot;">​</a></h2><p>MCP 是一套开放协议，用来标准化“AI 如何与外部世界交互”。你可以把它理解为 AI 的 <strong>USB-C 接口</strong>：</p><ul><li>插上就能读写本地文件、调用数据库、控制智能家居；</li><li>拔下就自动清理上下文，不留痕迹。<br> （MCP 只是一个协议， 它定义了 AI 与外部世界交互的规则， 但是具体的实现由外部世界的开发者来完成。）</li></ul><p>我目前接触到的 MCP，是 vscode 中的 Cline 插件，它利用 MCP 协议，实现了与外部世界的交互。</p>',24)]))}const P=a(p,[["render",l]]);export{h as __pageData,P as default};
