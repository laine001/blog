## LLM
LLM 即 Large Language Model，大语言模型。
是一种基于深度学习的自然语言处理技术，通过海量文本数据训练，能够生成或理解自然语言文本。 可以把它想象成一个阅读了海量信息（书籍、文章、网页），
并记住了其中语言模式和知识的“超级学生”。

LLM只处理文字，在一些多模态AI助手中的音频解析等能力是结合了视频或音频模型的。
例如，你上传一张猫咪照片并提问：“它在做什么？”
多模态系统会先用视觉模型“看图说话”，提炼出毛色、姿态、环境等关键信息；  
接着将这些视觉特征转成文本描述，交由 LLM 最终润色输出：“这只猫正慵懒地躺在洒满阳光的窗台上，伸着爪子打哈欠。”

## Agent
Agent原义代理，它不是“你问一句它答一句”的聊天机器人，而是你给它一个目标，它就能像真人一样**查资料、做决策、调用工具**，直到任务完成。  
Agent = LLM 的“行动版” —— 它不只聊天，还能调用工具、自主决策、帮你搞定任务，所以也成为智能体。
- LLM 是“大脑”（负责理解语言）
- Agent 是“大脑+手脚”（理解后主动执行）

> 个人理解：我们在使用的多数ai助手都是基于LLM的半agent，且正在向全agent方向发展。比如你说让ai帮你定机票，它可能会帮你查找航班信息并推荐合适的航班，但并不会帮你支付下单机票。

## Prompt
Prompt原意：提示，可以理解为LLM**理解问题的方式**。 它可以再分为**User Prompt和 System Prompt**。

### User Prompt 和 是System Prompt

从2023年OpenAI发布GPT-3模型一直到目前，多数AI看起来只是一个聊天框，我们通过聊天框发送一条消息给AI模型，然后AI模型再生成
一条回复消息，这个过程我们称之为对话。而我们发送的聊天消息，称之为User Prompt，也就是用户提示词，大部分的User Prompt一般
都是我们提出的问题或者想说的话。
而在我们发送的消息的时候，有些场景需要AI扮演某些角色，比如你想问AI office相关的问题，那么你就可以在提出问题之前先发送一条消息：
“你是一名精通office的专家”，又或者你想咨询法律相关的问题，你可以发送：“你是一位xx方面的法律专家，打赢过无数场官司”，
此时我们发送的这些提示词就是User Prompt。

但是很多时候你在使用ai的时候，会有各种各样的问题和想法，来回给ai提示就会比较麻烦，所以在各个ai助手的软件或网站上就出现了各种各样的“角色”，
它是系统提前设定好“背景、语气、角色、性格”等方面的内容，当你需要什么样的“角色”时，直接新开会话即可，这些提前设定好的“角色”，是系统
预设好的提示词，我们称之为System Prompt。

### 为什么需要Prompt

当我们和人对话提出一个问题或者说出一句话时，即使是同样的语气，同样的词语，不同的人都会有不同的理解，回复的内容也会有差异。

比如我和不同的人说同样的话，我说：我有点头疼

爸妈：怎么回事，吃药了没有，去医院看看吗

领导：需要请假回去休息吗

朋友：“这是好事啊” （沙僧表情包）

因为ai是给所有用户使用的，它必须衡量各个方面，然后给你一个通用的回答，所以如果你想让ai充当什么样的角色，就需要提前发送Prompt。


## MCP（Model Context Protocol）
MCP 是一套开放协议，用来标准化“AI 如何与外部世界交互”。你可以把它理解为AI的 **USB-C 接口**： 
- 插上就能读写本地文件、调用数据库、控制智能家居；  
- 拔下就自动清理上下文，不留痕迹。  
（MCP只是一个协议， 它定义了AI与外部世界交互的规则， 但是具体的实现由外部世界的开发者来完成。）

我目前接触到的MCP，是vscode中的Cline插件，它利用MCP协议，实现了与外部世界的交互。



